{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole dataset: (887, 6) (887,)\n",
      "training set: (665, 6) (665,)\n",
      "test set: (222, 6) (222,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "print(\"whole dataset:\", X.shape, y.shape)\n",
    "print(\"training set:\", X_train.shape, y_train.shape)\n",
    "print(\"test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8075187969924812\n",
      "accuracy: 0.7882882882882883\n",
      "precision: 0.7435897435897436\n",
      "recall: 0.6823529411764706\n",
      "f1 score: 0.7116564417177913\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision:\", precision_score(y_test, y_pred))\n",
    "print(\"recall:\", recall_score(y_test, y_pred))\n",
    "print(\"f1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [[3, 3], [1, 1], [4, 4]]\n",
      "X_test [[2, 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [[1, 1], [2, 2], [3, 3], [4, 4]]\n",
    "y = [0, 0, 1, 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 27)\n",
    "print('X_train', X_train)\n",
    "print('X_test', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity: 0.6829268292682927\n",
      "specificity: 0.9214285714285714\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_recall_fscore_support\n",
    "\n",
    "sensitivity_score = recall_score\n",
    "def specificity_score(y_true, y_pred):\n",
    "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    return r[0] #r [0] = специфичность r [1] = чувствительность \n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"sensitivity:\", sensitivity_score(y_test, y_pred))\n",
    "print(\"specificity:\", specificity_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46054586, 0.53945414],\n",
       "       [0.88810046, 0.11189954],\n",
       "       [0.1352057 , 0.8647943 ],\n",
       "       [0.6249705 , 0.3750295 ],\n",
       "       [0.73722879, 0.26277121],\n",
       "       [0.85687117, 0.14312883],\n",
       "       [0.84133207, 0.15866793],\n",
       "       [0.10657131, 0.89342869],\n",
       "       [0.12609697, 0.87390303],\n",
       "       [0.4202425 , 0.5797575 ],\n",
       "       [0.92436682, 0.07563318],\n",
       "       [0.83523984, 0.16476016],\n",
       "       [0.13698985, 0.86301015],\n",
       "       [0.90217345, 0.09782655],\n",
       "       [0.60512348, 0.39487652],\n",
       "       [0.79564753, 0.20435247],\n",
       "       [0.17515414, 0.82484586],\n",
       "       [0.46654813, 0.53345187],\n",
       "       [0.24195979, 0.75804021],\n",
       "       [0.89247748, 0.10752252],\n",
       "       [0.2846766 , 0.7153234 ],\n",
       "       [0.87814666, 0.12185334],\n",
       "       [0.86200232, 0.13799768],\n",
       "       [0.87075324, 0.12924676],\n",
       "       [0.86658907, 0.13341093],\n",
       "       [0.22589878, 0.77410122],\n",
       "       [0.85172102, 0.14827898],\n",
       "       [0.85167715, 0.14832285],\n",
       "       [0.56230501, 0.43769499],\n",
       "       [0.64036495, 0.35963505],\n",
       "       [0.89256744, 0.10743256],\n",
       "       [0.04988491, 0.95011509],\n",
       "       [0.51041734, 0.48958266],\n",
       "       [0.87120602, 0.12879398],\n",
       "       [0.94761349, 0.05238651],\n",
       "       [0.91062457, 0.08937543],\n",
       "       [0.03650827, 0.96349173],\n",
       "       [0.59265844, 0.40734156],\n",
       "       [0.62739628, 0.37260372],\n",
       "       [0.95937497, 0.04062503],\n",
       "       [0.22725279, 0.77274721],\n",
       "       [0.90920952, 0.09079048],\n",
       "       [0.35264793, 0.64735207],\n",
       "       [0.54177086, 0.45822914],\n",
       "       [0.44435409, 0.55564591],\n",
       "       [0.82171298, 0.17828702],\n",
       "       [0.74247637, 0.25752363],\n",
       "       [0.89824891, 0.10175109],\n",
       "       [0.86183008, 0.13816992],\n",
       "       [0.26830575, 0.73169425],\n",
       "       [0.78056554, 0.21943446],\n",
       "       [0.84654365, 0.15345635],\n",
       "       [0.69983164, 0.30016836],\n",
       "       [0.3269585 , 0.6730415 ],\n",
       "       [0.85116745, 0.14883255],\n",
       "       [0.72243714, 0.27756286],\n",
       "       [0.07465456, 0.92534544],\n",
       "       [0.04492803, 0.95507197],\n",
       "       [0.87393711, 0.12606289],\n",
       "       [0.33717739, 0.66282261],\n",
       "       [0.85178243, 0.14821757],\n",
       "       [0.14217302, 0.85782698],\n",
       "       [0.84102736, 0.15897264],\n",
       "       [0.92329004, 0.07670996],\n",
       "       [0.85160873, 0.14839127],\n",
       "       [0.90966505, 0.09033495],\n",
       "       [0.96516942, 0.03483058],\n",
       "       [0.68062911, 0.31937089],\n",
       "       [0.37301869, 0.62698131],\n",
       "       [0.49744302, 0.50255698],\n",
       "       [0.69670193, 0.30329807],\n",
       "       [0.87148895, 0.12851105],\n",
       "       [0.07718513, 0.92281487],\n",
       "       [0.60170066, 0.39829934],\n",
       "       [0.61536721, 0.38463279],\n",
       "       [0.04765466, 0.95234534],\n",
       "       [0.05302521, 0.94697479],\n",
       "       [0.95974077, 0.04025923],\n",
       "       [0.84931302, 0.15068698],\n",
       "       [0.72370169, 0.27629831],\n",
       "       [0.99575386, 0.00424614],\n",
       "       [0.88850025, 0.11149975],\n",
       "       [0.28460518, 0.71539482],\n",
       "       [0.85758344, 0.14241656],\n",
       "       [0.28483461, 0.71516539],\n",
       "       [0.90709088, 0.09290912],\n",
       "       [0.51997034, 0.48002966],\n",
       "       [0.91875707, 0.08124293],\n",
       "       [0.60923641, 0.39076359],\n",
       "       [0.89636166, 0.10363834],\n",
       "       [0.94247925, 0.05752075],\n",
       "       [0.31752892, 0.68247108],\n",
       "       [0.73816481, 0.26183519],\n",
       "       [0.95340174, 0.04659826],\n",
       "       [0.37742225, 0.62257775],\n",
       "       [0.83558848, 0.16441152],\n",
       "       [0.93778983, 0.06221017],\n",
       "       [0.69670193, 0.30329807],\n",
       "       [0.17416057, 0.82583943],\n",
       "       [0.80299356, 0.19700644],\n",
       "       [0.13201767, 0.86798233],\n",
       "       [0.92443726, 0.07556274],\n",
       "       [0.91885106, 0.08114894],\n",
       "       [0.90372886, 0.09627114],\n",
       "       [0.10674356, 0.89325644],\n",
       "       [0.23086929, 0.76913071],\n",
       "       [0.86616147, 0.13383853],\n",
       "       [0.82705087, 0.17294913],\n",
       "       [0.88855414, 0.11144586],\n",
       "       [0.92050586, 0.07949414],\n",
       "       [0.62238384, 0.37761616],\n",
       "       [0.10211797, 0.89788203],\n",
       "       [0.86956928, 0.13043072],\n",
       "       [0.51857597, 0.48142403],\n",
       "       [0.89507466, 0.10492534],\n",
       "       [0.84642781, 0.15357219],\n",
       "       [0.89254079, 0.10745921],\n",
       "       [0.1152408 , 0.8847592 ],\n",
       "       [0.86680442, 0.13319558],\n",
       "       [0.66905571, 0.33094429],\n",
       "       [0.29333053, 0.70666947],\n",
       "       [0.12007589, 0.87992411],\n",
       "       [0.85677742, 0.14322258],\n",
       "       [0.84114499, 0.15885501],\n",
       "       [0.49063055, 0.50936945],\n",
       "       [0.4464007 , 0.5535993 ],\n",
       "       [0.77480086, 0.22519914],\n",
       "       [0.91062457, 0.08937543],\n",
       "       [0.74856115, 0.25143885],\n",
       "       [0.64318918, 0.35681082],\n",
       "       [0.72220966, 0.27779034],\n",
       "       [0.9609083 , 0.0390917 ],\n",
       "       [0.82171298, 0.17828702],\n",
       "       [0.2321544 , 0.7678456 ],\n",
       "       [0.91394177, 0.08605823],\n",
       "       [0.82643042, 0.17356958],\n",
       "       [0.9506442 , 0.0493558 ],\n",
       "       [0.89656799, 0.10343201],\n",
       "       [0.5717084 , 0.4282916 ],\n",
       "       [0.8861578 , 0.1138422 ],\n",
       "       [0.94355148, 0.05644852],\n",
       "       [0.59883083, 0.40116917],\n",
       "       [0.8248545 , 0.1751455 ],\n",
       "       [0.10489947, 0.89510053],\n",
       "       [0.12055102, 0.87944898],\n",
       "       [0.87597446, 0.12402554],\n",
       "       [0.71190309, 0.28809691],\n",
       "       [0.08343387, 0.91656613],\n",
       "       [0.93670081, 0.06329919],\n",
       "       [0.82770653, 0.17229347],\n",
       "       [0.43972149, 0.56027851],\n",
       "       [0.28838316, 0.71161684],\n",
       "       [0.91730384, 0.08269616],\n",
       "       [0.92597487, 0.07402513],\n",
       "       [0.92610333, 0.07389667],\n",
       "       [0.25730166, 0.74269834],\n",
       "       [0.72341696, 0.27658304],\n",
       "       [0.87823074, 0.12176926],\n",
       "       [0.91512709, 0.08487291],\n",
       "       [0.9141048 , 0.0858952 ],\n",
       "       [0.05760729, 0.94239271],\n",
       "       [0.94078833, 0.05921167],\n",
       "       [0.16335017, 0.83664983],\n",
       "       [0.92524526, 0.07475474],\n",
       "       [0.9439369 , 0.0560631 ],\n",
       "       [0.94598015, 0.05401985],\n",
       "       [0.10242747, 0.89757253],\n",
       "       [0.62161619, 0.37838381],\n",
       "       [0.68571595, 0.31428405],\n",
       "       [0.895859  , 0.104141  ],\n",
       "       [0.04083057, 0.95916943],\n",
       "       [0.18785141, 0.81214859],\n",
       "       [0.4525546 , 0.5474454 ],\n",
       "       [0.67787708, 0.32212292],\n",
       "       [0.8921114 , 0.1078886 ],\n",
       "       [0.2395362 , 0.7604638 ],\n",
       "       [0.88854269, 0.11145731],\n",
       "       [0.1098782 , 0.8901218 ],\n",
       "       [0.94019684, 0.05980316],\n",
       "       [0.93882585, 0.06117415],\n",
       "       [0.79577605, 0.20422395],\n",
       "       [0.49522414, 0.50477586],\n",
       "       [0.75867133, 0.24132867],\n",
       "       [0.90727027, 0.09272973],\n",
       "       [0.90365328, 0.09634672],\n",
       "       [0.06064435, 0.93935565],\n",
       "       [0.56528457, 0.43471543],\n",
       "       [0.82987367, 0.17012633],\n",
       "       [0.8644531 , 0.1355469 ],\n",
       "       [0.46033876, 0.53966124],\n",
       "       [0.84642781, 0.15357219],\n",
       "       [0.33928177, 0.66071823],\n",
       "       [0.87603483, 0.12396517],\n",
       "       [0.8464835 , 0.1535165 ],\n",
       "       [0.70686054, 0.29313946],\n",
       "       [0.85126423, 0.14873577],\n",
       "       [0.47905843, 0.52094157],\n",
       "       [0.92539633, 0.07460367],\n",
       "       [0.2395362 , 0.7604638 ],\n",
       "       [0.89643908, 0.10356092],\n",
       "       [0.65157887, 0.34842113],\n",
       "       [0.53351488, 0.46648512],\n",
       "       [0.84638869, 0.15361131],\n",
       "       [0.32586273, 0.67413727],\n",
       "       [0.86966214, 0.13033786],\n",
       "       [0.6728885 , 0.3271115 ],\n",
       "       [0.66905571, 0.33094429],\n",
       "       [0.37932651, 0.62067349],\n",
       "       [0.63392106, 0.36607894],\n",
       "       [0.95150931, 0.04849069],\n",
       "       [0.90433822, 0.09566178],\n",
       "       [0.95359157, 0.04640843],\n",
       "       [0.20277657, 0.79722343],\n",
       "       [0.03729425, 0.96270575],\n",
       "       [0.72358305, 0.27641695],\n",
       "       [0.07284715, 0.92715285],\n",
       "       [0.54861255, 0.45138745],\n",
       "       [0.88858281, 0.11141719],\n",
       "       [0.84113879, 0.15886121],\n",
       "       [0.68742258, 0.31257742],\n",
       "       [0.72019864, 0.27980136],\n",
       "       [0.88458659, 0.11541341]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict_proba(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53945414, 0.11189954, 0.8647943 , 0.3750295 , 0.26277121,\n",
       "       0.14312883, 0.15866793, 0.89342869, 0.87390303, 0.5797575 ,\n",
       "       0.07563318, 0.16476016, 0.86301015, 0.09782655, 0.39487652,\n",
       "       0.20435247, 0.82484586, 0.53345187, 0.75804021, 0.10752252,\n",
       "       0.7153234 , 0.12185334, 0.13799768, 0.12924676, 0.13341093,\n",
       "       0.77410122, 0.14827898, 0.14832285, 0.43769499, 0.35963505,\n",
       "       0.10743256, 0.95011509, 0.48958266, 0.12879398, 0.05238651,\n",
       "       0.08937543, 0.96349173, 0.40734156, 0.37260372, 0.04062503,\n",
       "       0.77274721, 0.09079048, 0.64735207, 0.45822914, 0.55564591,\n",
       "       0.17828702, 0.25752363, 0.10175109, 0.13816992, 0.73169425,\n",
       "       0.21943446, 0.15345635, 0.30016836, 0.6730415 , 0.14883255,\n",
       "       0.27756286, 0.92534544, 0.95507197, 0.12606289, 0.66282261,\n",
       "       0.14821757, 0.85782698, 0.15897264, 0.07670996, 0.14839127,\n",
       "       0.09033495, 0.03483058, 0.31937089, 0.62698131, 0.50255698,\n",
       "       0.30329807, 0.12851105, 0.92281487, 0.39829934, 0.38463279,\n",
       "       0.95234534, 0.94697479, 0.04025923, 0.15068698, 0.27629831,\n",
       "       0.00424614, 0.11149975, 0.71539482, 0.14241656, 0.71516539,\n",
       "       0.09290912, 0.48002966, 0.08124293, 0.39076359, 0.10363834,\n",
       "       0.05752075, 0.68247108, 0.26183519, 0.04659826, 0.62257775,\n",
       "       0.16441152, 0.06221017, 0.30329807, 0.82583943, 0.19700644,\n",
       "       0.86798233, 0.07556274, 0.08114894, 0.09627114, 0.89325644,\n",
       "       0.76913071, 0.13383853, 0.17294913, 0.11144586, 0.07949414,\n",
       "       0.37761616, 0.89788203, 0.13043072, 0.48142403, 0.10492534,\n",
       "       0.15357219, 0.10745921, 0.8847592 , 0.13319558, 0.33094429,\n",
       "       0.70666947, 0.87992411, 0.14322258, 0.15885501, 0.50936945,\n",
       "       0.5535993 , 0.22519914, 0.08937543, 0.25143885, 0.35681082,\n",
       "       0.27779034, 0.0390917 , 0.17828702, 0.7678456 , 0.08605823,\n",
       "       0.17356958, 0.0493558 , 0.10343201, 0.4282916 , 0.1138422 ,\n",
       "       0.05644852, 0.40116917, 0.1751455 , 0.89510053, 0.87944898,\n",
       "       0.12402554, 0.28809691, 0.91656613, 0.06329919, 0.17229347,\n",
       "       0.56027851, 0.71161684, 0.08269616, 0.07402513, 0.07389667,\n",
       "       0.74269834, 0.27658304, 0.12176926, 0.08487291, 0.0858952 ,\n",
       "       0.94239271, 0.05921167, 0.83664983, 0.07475474, 0.0560631 ,\n",
       "       0.05401985, 0.89757253, 0.37838381, 0.31428405, 0.104141  ,\n",
       "       0.95916943, 0.81214859, 0.5474454 , 0.32212292, 0.1078886 ,\n",
       "       0.7604638 , 0.11145731, 0.8901218 , 0.05980316, 0.06117415,\n",
       "       0.20422395, 0.50477586, 0.24132867, 0.09272973, 0.09634672,\n",
       "       0.93935565, 0.43471543, 0.17012633, 0.1355469 , 0.53966124,\n",
       "       0.15357219, 0.66071823, 0.12396517, 0.1535165 , 0.29313946,\n",
       "       0.14873577, 0.52094157, 0.07460367, 0.7604638 , 0.10356092,\n",
       "       0.34842113, 0.46648512, 0.15361131, 0.67413727, 0.13033786,\n",
       "       0.3271115 , 0.33094429, 0.62067349, 0.36607894, 0.04849069,\n",
       "       0.09566178, 0.04640843, 0.79722343, 0.96270575, 0.27641695,\n",
       "       0.92715285, 0.45138745, 0.11141719, 0.15886121, 0.31257742,\n",
       "       0.27980136, 0.11541341])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False, False, False,  True,  True,\n",
       "        True, False, False,  True, False, False, False,  True,  True,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "        True, False, False, False,  True, False,  True, False,  True,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False, False,  True,  True, False,  True, False,  True, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True,  True, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False,  True,  True, False, False,  True,  True,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True, False, False,  True, False, False,  True,  True, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "        True, False, False, False,  True, False, False, False,  True,\n",
       "        True,  True, False, False,  True, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False,  True,  True, False,  True,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)[:,1] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.835820895522388\n",
      "recall: 0.6829268292682927\n"
     ]
    }
   ],
   "source": [
    "print('precision:', precision_score(y_test, y_pred))\n",
    "print('recall:', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('1 - specificity')\n",
    "plt.ylabel('sensitivity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8572299651567944"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "(roc_auc_score (y_test, y_pred_proba [:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 AUC score: 0.8396812888538657\n",
      "model 1 AUC score: 0.8230014884861221\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred_proba1 = model1.predict_proba(X_test)\n",
    "print(\"model 1 AUC score:\", roc_auc_score(y_test, y_pred_proba1[:, 1]))\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train[:, 0:2], y_train)\n",
    "y_pred_proba2 = model2.predict_proba(X_test[:, 0:2])\n",
    "print(\"model 1 AUC score:\", roc_auc_score(y_test, y_pred_proba2[:, 1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy: 0.78378\n",
      "precision: 0.73171\n",
      "   recall: 0.69767\n",
      " f1 score: 0.71429\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# building the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\" accuracy: {0:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"precision: {0:.5f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"   recall: {0:.5f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\" f1 score: {0:.5f}\".format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.      7.25  ]\n",
      " [38.     71.2833]\n",
      " [26.      7.925 ]\n",
      " [35.     53.1   ]\n",
      " [35.      8.05  ]\n",
      " [27.      8.4583]] [0 1 1 1 0 0]\n",
      "[0 1 4 5] [2 3]\n",
      "[0 1 2 3] [4 5]\n",
      "[2 3 4 5] [0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "X = df[['Age','Fare']].values[:6]\n",
    "y = df['Survived'].values[:6]\n",
    "print(X, y)\n",
    "kf = KFold(n_splits = 3, shuffle = True ) \n",
    "for train, test in kf.split(X):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 3, 4, 5]), array([0, 2]))\n"
     ]
    }
   ],
   "source": [
    "splits = list(kf.split(X))\n",
    "first_split = splits[0]\n",
    "print(first_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set indices: [1 3 4 5]\n",
      "test set indices: [0 2]\n"
     ]
    }
   ],
   "source": [
    "train_indices, test_indices = first_split\n",
    "print('training set indices:', train_indices)\n",
    "print('test set indices:', test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "[[38.     71.2833]\n",
      " [35.     53.1   ]\n",
      " [35.      8.05  ]\n",
      " [27.      8.4583]]\n",
      "y_train [1 1 0 0]\n",
      "X_test\n",
      "[[22.     7.25 ]\n",
      " [26.     7.925]]\n",
      "y_test [0 1]\n"
     ]
    }
   ],
   "source": [
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "print(\"y_train\", y_train)\n",
    "print(\"X_test\")\n",
    "print(X_test)\n",
    "print(\"y_test\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8595505617977528\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LogiscticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-3713889eac56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogiscticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogiscticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "splits = list(kf.split(X))\n",
    "train_indices, test_indices = splits[0]\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7921348314606742, 0.7752808988764045, 0.8022598870056498, 0.8361581920903954, 0.807909604519774]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8027486827905795\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression()\n",
    "final_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "X2 = df[['Pclass', 'male', 'Age']].values\n",
    "X3 = df[['Fare', 'Age']].values\n",
    "y = df['Survived'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with all features\n",
      "accuracy: 0.8027105948073382\n",
      "precision: 0.7702564102564102\n",
      "recall: 0.7022277865254762\n",
      "f1 score: 0.7336434882443968\n",
      "\n",
      "Logistic Regression with Pclass, Sex & Age features\n",
      "accuracy: 0.7948009902875642\n",
      "precision: 0.7459970075437363\n",
      "recall: 0.7075108116561912\n",
      "f1 score: 0.7252604400740165\n",
      "\n",
      "Logistic Regression with Fare & Age features\n",
      "accuracy: 0.6595315178061322\n",
      "precision: 0.6637511297425149\n",
      "recall: 0.2395736203823437\n",
      "f1 score: 0.34846520133405673\n"
     ]
    }
   ],
   "source": [
    "def score_model(X, y, kf):\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "    print(\"accuracy:\", np.mean(accuracy_scores))\n",
    "    print(\"precision:\", np.mean(precision_scores))\n",
    "    print(\"recall:\", np.mean(recall_scores))\n",
    "    print(\"f1 score:\", np.mean(f1_scores))\n",
    "print(\"Logistic Regression with all features\")\n",
    "score_model(X1, y, kf)\n",
    "print()\n",
    "print(\"Logistic Regression with Pclass, Sex & Age features\")\n",
    "score_model(X2, y, kf)\n",
    "print()\n",
    "print(\"Logistic Regression with Fare & Age features\")\n",
    "score_model(X3, y, kf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression () \n",
    "model.fit (X1, y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[3, False, 25, 0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
